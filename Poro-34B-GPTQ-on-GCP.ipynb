{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbe2c571-deea-437c-925f-9e1ec53e38ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Poro quantized LLM model By TheBloke implemented on VertexAI GCP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aec5c424-d358-4338-8507-776696fa5f46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model: https://huggingface.co/TheBloke/Poro-34B-GPTQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1463b2b-6258-4652-8a7a-1034e322563d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCP instance\n",
    "# Debian 11 + Python 3 (with Intel MKL and CUDA 11.8)\n",
    "# 2 x L4 NVIDIA GPUs\n",
    "# 24 vCPUs, 96 GB RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "504b02f6-a6c1-4c2e-91a1-e323a9b17e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# environment: install requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83a1155-4b5d-420e-9e1f-03192a48c2f4",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e229e896-4bd9-45ac-95f3-c7bb1daee4b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16655fa9-13bb-48bd-88f8-8e242469b2d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0+cu121'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a88f1730-fbe8-48d3-a745-6dc526d49dde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c858783d-32b5-404f-bc6b-6357aef74985",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea93e401-8c06-4470-bf47-132a8ef19c79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cf2f2ff8-4450-4330-a70a-e2c1233cebe6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfd8e83-d3be-4ce2-93bd-04a2a5357884",
   "metadata": {},
   "source": [
    "### Quantized model using GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43d2d1c4-3f06-4ab2-8ae1-10ff5073803c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name_or_path = \"TheBloke/Poro-34B-GPTQ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76636169-f10b-4302-b422-39a6631d13bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 286/286 [00:00<00:00, 172kB/s]\n",
      "tokenizer.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.64M/5.64M [00:00<00:00, 8.21MB/s]\n",
      "special_tokens_map.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 545/545 [00:00<00:00, 334kB/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36056c94-bfec-42b4-90d3-f047c894c617",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.00k/1.00k [00:00<00:00, 249kB/s]\n",
      "model.safetensors: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22.9G/22.9G [24:24<00:00, 15.7MB/s]\n",
      "generation_config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 132/132 [00:00<00:00, 80.0kB/s]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path,\n",
    "                                             device_map=\"auto\",\n",
    "                                             trust_remote_code=False,\n",
    "                                             revision=\"gptq-4bit-32g-actorder_True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ee064d-25f6-4392-a0a0-e3a1d86add77",
   "metadata": {},
   "source": [
    "### Prompt and prompt template (in English)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4607164a-ef22-4adf-9da6-cb5bff280a35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"It was a dark and stormy night\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a88f179-123c-4f65-b101-1317af0ba365",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template=f'''{prompt}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26902b09-91f0-4f96-a798-8b5d10559316",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "505d9dc3-bc62-4b39-badd-f6fa0b058589",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_ids = tokenizer(prompt_template, return_tensors='pt').input_ids.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c798a152-f2d9-4573-a69e-f33802ac1d59",
   "metadata": {},
   "source": [
    "### Output using model.generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "79d2fb3f-1c7c-44d9-83d2-51e2e46dc837",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = model.generate(inputs=input_ids, temperature=0.7, do_sample=True, top_p=0.9, top_k=50, max_new_tokens=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "80835c14-4959-43a2-b5bd-115fdc3004a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was a dark and stormy night\n",
      "I was a young man, on my first night shift in the ER. It was just me, the resident and the charge nurse. We were all alone in the ER, and it was very quiet. All of a sudden, I heard a loud bang, and the lights went out. I looked up to see what had caused the bang, and I saw a huge shadowy figure standing in the middle of the room. I was terrified, but I had to do my job, so I went to investigate. As I got closer to the figure, I could see that it was a giant black dog with glowing red eyes. I screamed and ran back to the nurse's station, but the dog was already on me. I tried to fight it off, but it was too strong. It bit me hard, and I fell to the floor. I screamed again, and the nurse came running. She saw the dog and screamed, too. She grabbed me and pulled me to safety. As we were running, I could hear the dog growling and barking at us. We made it to the nurse's station, and the nurse called the police. The police came quickly, and they shot the dog with a tranquilizer dart. The dog fell to the floor, and the police took it away. I was taken to the hospital, where I was treated for my injuries. The next day, I went back to work, but I never forgot that night. It was a dark and stormy night, and I will never forget the giant black dog with glowing red eyes.\n",
      "The dog was a black lab, and he had been wandering around the neighborhood for a while. He was hungry and tired, and he was looking for someone to help him. He saw me, and he knew that I was a good person. He came up to me and asked if I could help him. I told him that I could, and we went to the nearest grocery store. I bought some food for the dog, and we went home. The dog was very happy, and he thanked me for helping him. He promised to be good and to never hurt anyone again. I promised to keep an eye on him, and I have been doing just that. The dog is now a very happy and contented member of my family. He is a good boy, and he has been a great addition to my life. The dog and I are very happy, and I hope that we can be together for a long time.\n",
      "There was a dark and\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66365bf-8264-4151-8bab-6102fb92ea1c",
   "metadata": {},
   "source": [
    "### Ourput using transformers' pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a32be667-e8f9-4655-bf4a-e1d8c32fbd33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    do_sample=True,\n",
    "    temperature=0.5,\n",
    "    top_p=0.9,\n",
    "    top_k=50,\n",
    "    repetition_penalty=1.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d9deff39-d1ba-4996-82b3-dd1ee5f6a7dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was a dark and stormy night\n",
      "I went to the window, I looked out on the rain,\n",
      "And what should I see?\n",
      "But only darkness.\n",
      "The next morning when I woke up it had stopped raining. The clouds were gone from over my head!\n",
      "How do you know that God is real? How can we prove his existence if he doesn't exist in this world of matter like us humans are made of (or at least that's how science says)?\n",
      "Well‚Ä¶the Bible has been proven by scientists time after time! It contains information about scientific events which happened thousands or millions years before they actually did happen!! And then there have also been other things discovered through research such as fossils found under water with dates written upon them showing these objects lived hundreds of thousands/millions ago!!\n",
      "There have even been some amazing archaeological discoveries lately where archaeologists find items left behind for centuries buried deep underground ‚Äì yet still perfectly preserved today!!! Archaeologist dig into the ground looking for artifacts but instead discover entire cities!!!\n",
      "Here is one example‚Ä¶\n",
      "https://www.youtube.com/watch?v=fZu7xRnW0lE&t=22s\n",
      "This video shows an incredible discovery recently uncovered in Israel: A city dating back 2,000 years!!!! This city could be considered the oldest known archeological site ever discovered!!!!\n",
      "Now here comes another thing that will blow your mind away‚Ä¶.\n",
      "Scientists just created life using chemicals extracted straight off Earth!!!!!!!!!\n",
      "Yes, Scientists used chemical elements taken directly form earth's crust along with energy from sunlight to create life-like organisms called Synthetic Biology Organisms (SBO) ‚Äì so basically synthetic biology organisms are living cells produced artificially rather than naturally occurring ones!!!! These SBO look almost exactly identical to natural bacteria except their DNA sequences differ slightly due to being synthesized using genetic engineering techniques rather than evolved naturally!!!\n",
      "These new creatures aren't alive per se though because they're not able to reproduce themselves without outside help; however it's very possible someday soon we'll learn more advanced ways to make them live independently!!! For now we're stuck having to keep feeding our creations every few days since they've got no way of making food for themselves whatsoever lol.\n",
      "If you're interested here's links below containing videos explaining all this:\n",
      "https://vimeo.com/283867120#t=0m0s\n",
      "https://youtu.be/gnYdLg4oJqA\n",
      "So yeah‚Ä¶if you've never read/watched anything related to Christianity I'd highly recommend doing so ASAP üôÇ It's definitely worth reading/listening too üòâ\n"
     ]
    }
   ],
   "source": [
    "print(pipe(prompt_template)[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59842e0-e4e6-4faf-a790-9665a49607aa",
   "metadata": {},
   "source": [
    "### Prompt in Finnish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5db03186-4bb9-496c-8d1a-bfd6e633266b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"Oli synkk√§ ja myrskyinen y√∂\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ca0c190-e2fd-4965-a66b-7763dd8c16dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template=f'''{prompt}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da26cb17-71b8-477e-90d0-584a0d2ed4e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_ids = tokenizer(prompt_template, return_tensors='pt').input_ids.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f4f998-dc15-4af1-bd74-e852fe8eab52",
   "metadata": {},
   "source": [
    "### Output with model.generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9a05c97-aae2-451b-be24-098b7acb3708",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = model.generate(inputs=input_ids, temperature=0.5, do_sample=True, top_p=0.9, top_k=50, max_new_tokens=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4890d1f9-8993-46de-86a6-a01a7fdb77aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oli synkk√§ ja myrskyinen y√∂\n",
      "Kun her√§sin, oli jo pime√§√§. En n√§hnyt mit√§√§n, mutta tunsin, ett√§ jotain oli vialla. Oli kylm√§ ja kostea, ja olin aivan yksin. Olin kuullut y√∂ll√§ outoja √§√§ni√§, mutta en ollut uskaltanut menn√§ katsomaan. Nyt olin varma, ett√§ jokin oli pieless√§. Menin varovasti ulos ja n√§in, ett√§ koko kaupunki oli pime√§n√§. Kaikkialla oli hiljaista. En n√§hnyt ket√§√§n, mutta kuulin, kuinka joku juoksi minua kohti. Juoksin nopeasti takaisin sis√§lle. En uskaltanut menn√§ ulos en√§√§ sin√§ y√∂n√§.</s>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c953daca-8636-4709-97b7-136d386ff157",
   "metadata": {},
   "source": [
    "### Output using pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "102dfb3c-02b1-4596-b600-574b3664aed8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    do_sample=True,\n",
    "    temperature=0.5,\n",
    "    top_p=0.9,\n",
    "    top_k=50,\n",
    "    repetition_penalty=1.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d3fb88f-c4ba-4ded-af27-5c9c05bfda8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oli synkk√§ ja myrskyinen y√∂\n",
      "kun saavuin kotiin.\n",
      "Ei ollut ket√§√§n kotona,\n",
      "ei edes kissaa n√§kynyt mailla halmeilla!\n",
      "Mit√§ ihmett√§?\n",
      "Mist√§ on kyse?!\n",
      "Kuka t√§√§ll√§ oikein asustaa...?\n",
      "Miss√§ kaikki ovat??\n",
      "|Kaikkialla oli vain tyhjyytt√§.|\n",
      "Lopulta l√∂ysin sen...\n",
      "Se istui s√§ngyll√§, tuijotti minua suoraan silmiin.\n",
      "|\"Hei! Min√§ olen kissa. Kuka sin√§ olet?|\n",
      "En ole n√§hnyt sinua koskaan aikaisemmin...\"\n",
      "|\"Mik√§ sinun nimesi on? En muista sit√§ en√§√§...\"|\n",
      "|\"Min√§ olen Kissa. Mit√§ sin√§ teet t√§√§ll√§?\"|\n",
      "|\"En tied√§. Olen eksynyt t√§nne joskus kauan sitten.|\n",
      "|\"Onko sinulla n√§lk√§? Minulla ainakin olisi..\"|\n",
      "|\"No ei minullakaan kyll√§ kovin hyvin mene....\"|\n",
      "|\"Kyll√§ t√§m√§ t√§st√§ viel√§ iloksi muuttuu...\"|\n",
      "|\"Ai niin! Minun nimeni onkin Pulla! \"|\n",
      "|\"Selv√§ juttu. Hei hei! N√§hd√§√§n taas!\"|\n",
      "|Ja n√§in p√§√§ttyi tarina Kissan ja Pullan kohtaamisesta.|\n",
      "Ei kommentteja:\n",
      "L√§het√§ kommentti\n"
     ]
    }
   ],
   "source": [
    "print(pipe(prompt_template)[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc5b5d2-4de4-4651-a5f3-681ff68bc009",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "poro",
   "name": "common-gpu.m116",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-gpu:m116"
  },
  "kernelspec": {
   "display_name": "Poro",
   "language": "python",
   "name": "poro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
